{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ca79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wafer_experiment_pkl.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "# -------------------\n",
    "# Config\n",
    "# -------------------\n",
    "class Cfg:\n",
    "    seed = 42\n",
    "    img_size = 128\n",
    "    batch_size = 96\n",
    "    num_workers = 0\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "    use_focal = True\n",
    "    focal_gamma = 1.0\n",
    "    use_class_weights = True\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    data_path = \"data/wafer_maps.pkl\"\n",
    "    out_dir = \"outputs/pkl_exp1\"\n",
    "\n",
    "\n",
    "os.makedirs(Cfg.out_dir, exist_ok=True)\n",
    "random.seed(Cfg.seed)\n",
    "np.random.seed(Cfg.seed)\n",
    "torch.manual_seed(Cfg.seed)\n",
    "if Cfg.device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(Cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a349df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "12.6\n",
      "True\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device() if torch.cuda.is_available() else \"No CUDA device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828f96e",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b98d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(Cfg.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239b17c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811452</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Ring]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811453</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Loc]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811454</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47542</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[[Test]]</td>\n",
       "      <td>[[Edge-Ring]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811455</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811456</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lot47543</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 waferMap  dieSize   lotName  \\\n",
       "811452  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47542   \n",
       "811453  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1,...    600.0  lot47542   \n",
       "811454  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47542   \n",
       "811455  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,...    600.0  lot47543   \n",
       "811456  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,...    600.0  lot47543   \n",
       "\n",
       "        waferIndex trianTestLabel    failureType  \n",
       "811452        23.0       [[Test]]  [[Edge-Ring]]  \n",
       "811453        24.0       [[Test]]   [[Edge-Loc]]  \n",
       "811454        25.0       [[Test]]  [[Edge-Ring]]  \n",
       "811455         1.0             []             []  \n",
       "811456         2.0             []             []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082b8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting typos if any\n",
    "if 'trianTestLabel' in df and 'trainTestLabel' not in df:\n",
    "    df['trainTestLabel']=df['trianTestLabel']\n",
    "    df.drop('trianTestLabel', axis=1, inplace=True)\n",
    "elif 'trianTestLabel' in df and 'trainTestLabel' in df:\n",
    "    df.drop('trianTestLabel', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f5ec0",
   "metadata": {},
   "source": [
    "Flattening TrainTestLabel and failureType values to be strings instead of single element arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f065c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_label(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        # 2D list with one inner list\n",
    "        if len(x) == 1 and isinstance(x[0], (list, np.ndarray)):\n",
    "            if len(x[0]) == 1:\n",
    "                return x[0][0]\n",
    "            elif len(x[0]) == 0:\n",
    "                return \"\"  # empty inner list\n",
    "            else:\n",
    "                return x[0]  # unclear case, return inner list as is\n",
    "        # 1D list\n",
    "        elif len(x) == 1:\n",
    "            return x[0]\n",
    "        elif len(x) == 0:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        # Not a list/array, return as is\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data points\n",
    "# Flatten trainTestLabel and failureType arrays: e.g. [[Training]] -> \"Training\"\n",
    "df[\"trainTestLabel\"] = df[\"trainTestLabel\"].apply(flatten_label)\n",
    "df[\"failureType\"] = df[\"failureType\"].apply(flatten_label)\n",
    "\n",
    "# Filter only Training data for training/validation split. \n",
    "# Note:I swapped Training and Test since Test has more samples than Training\n",
    "train_df = df[df[\"trainTestLabel\"] == \"Test\"].reset_index(drop=True)\n",
    "test_df = df[df[\"trainTestLabel\"] == \"Training\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76932de9",
   "metadata": {},
   "source": [
    "Assigning class labels to target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique classes and class to index mapping\n",
    "classes = sorted(train_df[\"failureType\"].unique())\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "# Map labels to integers\n",
    "train_df[\"label_idx\"] = train_df[\"failureType\"].map(class_to_idx)\n",
    "test_df[\"label_idx\"] = test_df[\"failureType\"].map(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d9abb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.str_('Center'): 0,\n",
       " np.str_('Donut'): 1,\n",
       " np.str_('Edge-Loc'): 2,\n",
       " np.str_('Edge-Ring'): 3,\n",
       " np.str_('Loc'): 4,\n",
       " np.str_('Near-full'): 5,\n",
       " np.str_('Random'): 6,\n",
       " np.str_('Scratch'): 7,\n",
       " np.str_('none'): 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc9f58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>failureType</th>\n",
       "      <th>trainTestLabel</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54350</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>lot46729</td>\n",
       "      <td>21.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54351</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>lot46729</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54352</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>lot46729</td>\n",
       "      <td>23.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54353</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>lot46729</td>\n",
       "      <td>24.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54354</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>lot46729</td>\n",
       "      <td>25.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54355 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                waferMap  dieSize   lotName  \\\n",
       "0      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0      lot1   \n",
       "1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0      lot1   \n",
       "2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0      lot1   \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0      lot1   \n",
       "4      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0      lot1   \n",
       "...                                                  ...      ...       ...   \n",
       "54350  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1534.0  lot46729   \n",
       "54351  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1534.0  lot46729   \n",
       "54352  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1534.0  lot46729   \n",
       "54353  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1534.0  lot46729   \n",
       "54354  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1534.0  lot46729   \n",
       "\n",
       "       waferIndex failureType trainTestLabel  label_idx  \n",
       "0             1.0        none       Training          8  \n",
       "1             2.0        none       Training          8  \n",
       "2             3.0        none       Training          8  \n",
       "3             4.0        none       Training          8  \n",
       "4             5.0        none       Training          8  \n",
       "...           ...         ...            ...        ...  \n",
       "54350        21.0        none       Training          8  \n",
       "54351        22.0        none       Training          8  \n",
       "54352        23.0        none       Training          8  \n",
       "54353        24.0        none       Training          8  \n",
       "54354        25.0        none       Training          8  \n",
       "\n",
       "[54355 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415038d3",
   "metadata": {},
   "source": [
    "### Saving partially processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c0e7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"data/wafer_train.pkl\")\n",
    "test_df.to_pickle(\"data/wafer_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select samples\n",
    "df_samples = test_df.sample(n=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59841f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>failureType</th>\n",
       "      <th>trainTestLabel</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1,...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>lot181</td>\n",
       "      <td>8.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46913</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1,...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>lot45075</td>\n",
       "      <td>24.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17707</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>lot15573</td>\n",
       "      <td>4.0</td>\n",
       "      <td>none</td>\n",
       "      <td>Training</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                waferMap  dieSize   lotName  \\\n",
       "3953   [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1,...    533.0    lot181   \n",
       "46913  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1,...    501.0  lot45075   \n",
       "17707  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1998.0  lot15573   \n",
       "\n",
       "       waferIndex failureType trainTestLabel  label_idx  \n",
       "3953          8.0        none       Training          8  \n",
       "46913        24.0        none       Training          8  \n",
       "17707         4.0        none       Training          8  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce61200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([3953, 46913, 17707], dtype='int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce75458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3953\n",
      "46913\n",
      "17707\n"
     ]
    }
   ],
   "source": [
    "# Save images as PNG with filename: waferIndex_defectCategory.png\n",
    "for _, row in df_samples.iterrows():\n",
    "    wafer_map = row[\"waferMap\"]\n",
    "    wafer_index = _\n",
    "    defect = row[\"failureType\"]\n",
    "    print(wafer_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d0e59",
   "metadata": {},
   "source": [
    "### Train val test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680ba79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"data/wafer_train.pkl\")\n",
    "test_df = pd.read_pickle(\"data/wafer_test.pkl\")\n",
    "classes = sorted(train_df[\"failureType\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd0f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "    train_df[\"waferMap\"].values, train_df[\"label_idx\"].values,\n",
    "    test_size=0.2, stratify=train_df[\"label_idx\"].values, random_state=Cfg.seed)\n",
    "\n",
    "# Extract test images and labels\n",
    "test_imgs = test_df[\"waferMap\"].values\n",
    "test_labels = test_df[\"label_idx\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0333f",
   "metadata": {},
   "source": [
    "### Dataset transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaferMapDataset(Dataset):\n",
    "    def __init__(self, wafer_maps, labels, transform=None):\n",
    "        self.wafer_maps = wafer_maps\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wafer_maps)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.wafer_maps[idx]\n",
    "        # Convert to uint8 image scaled 0-255\n",
    "        img = np.array(img)\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "        if img.max() > img.min():\n",
    "            img_norm = ((img - img.min()) / (img.max() - img.min()) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_norm = np.zeros_like(img, dtype=np.uint8)\n",
    "        img = Image.fromarray(img_norm)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea464e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((Cfg.img_size, Cfg.img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "        transforms.Resize((Cfg.img_size, Cfg.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcbd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# Create DataLoaders\n",
    "# -------------------\n",
    "train_ds = WaferMapDataset(train_imgs, train_labels, transform=train_transforms)\n",
    "val_ds = WaferMapDataset(val_imgs, val_labels, transform=val_test_transforms)\n",
    "test_ds = WaferMapDataset(test_imgs, test_labels, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=Cfg.batch_size, shuffle=True, num_workers=Cfg.num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=Cfg.batch_size, shuffle=False, num_workers=Cfg.num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=Cfg.batch_size, shuffle=False, num_workers=Cfg.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0067a",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ace8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1).to(Cfg.device)\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_model(len(classes)).to(Cfg.device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', ignore_index=-100):\n",
    "        \"\"\"\n",
    "        alpha: Tensor of shape (num_classes,) giving weight per class. If None, no weighting.\n",
    "        gamma: focusing parameter >=0, default 2.0.\n",
    "        reduction: 'mean', 'sum', or 'none'\n",
    "        ignore_index: class index to ignore in loss.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=None, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if not torch.is_tensor(self.alpha):\n",
    "                self.alpha = torch.tensor(self.alpha, dtype=torch.float32)\n",
    "            self.alpha = self.alpha.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, num_classes) raw logits (no softmax applied)\n",
    "        targets: (batch_size,) ground truth class indices (long)\n",
    "        \"\"\"\n",
    "        # Compute cross entropy loss per sample\n",
    "        ce_loss = self.ce_loss(inputs, targets)  # shape: (batch_size,)\n",
    "\n",
    "        # Calculate pt = exp(-CE)\n",
    "        pt = torch.exp(-ce_loss)  # pt is probability of true class\n",
    "\n",
    "        # Compute focal loss modulation\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        # Apply alpha class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha.gather(0, targets)\n",
    "            focal_loss = at * focal_loss\n",
    "\n",
    "        # Reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "#from collections import Counter\n",
    "class_weights = None\n",
    "if Cfg.use_class_weights:\n",
    "    label_counts = Counter(train_labels)\n",
    "    weights = np.array([1.0 / max(1, label_counts[i]) for i in range(len(classes))], dtype=np.float32)\n",
    "    weights = weights / weights.sum() * len(classes)\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float32, device=Cfg.device)\n",
    "\n",
    "criterion = FocalLoss(gamma=Cfg.focal_gamma, weight=class_weights) if Cfg.use_focal else nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=Cfg.lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Cfg.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5d687",
   "metadata": {},
   "source": [
    "### Sample training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bf872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Test your .to() with non_blocking argument\n",
    "x = torch.randn(2,2)\n",
    "y = x.to(\"cuda\", non_blocking=True)  # should work without error\n",
    "print(y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc76ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Input tensor device: cuda:0\n",
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1).to(device)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n",
    "model.to(device)\n",
    "\n",
    "dummy_img = np.random.randint(0, 255, (64,64))\n",
    "dummy_img = Image.fromarray(dummy_img.astype(np.uint8)).convert(\"RGB\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485]*3, [0.229]*3)\n",
    "])\n",
    "\n",
    "img_tensor = transform(dummy_img).unsqueeze(0).to(device)\n",
    "print(f\"Input tensor device: {img_tensor.device}\")\n",
    "\n",
    "output = model(img_tensor)\n",
    "print(f\"Output device: {output.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3f09a",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd3cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for model parameters: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                       | 0/742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  12%|███▌                          | 88/742 [00:42<05:13,  2.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDevice for model parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(model.parameters()).device\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m train_loader = tqdm.tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCfg.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, ncols=\u001b[32m80\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(\"Got batch shapes:\", images.shape, labels.shape)\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#images, labels = images.to(Cfg.device), labels.to(Cfg.device)\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <-- move to GPU\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <-- move to GPU\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\tqdm\\std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mWaferMapDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     17\u001b[39m img = Image.fromarray(np.clip(img,\u001b[32m0\u001b[39m,np.percentile(img, \u001b[32m99\u001b[39m)).astype(np.uint8))  \u001b[38;5;66;03m# clip outliers for better contrast\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# # Ensure img is Tensor\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# if not torch.is_tensor(img):\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     img = torch.as_tensor(img)\u001b[39;00m\n\u001b[32m     25\u001b[39m label = \u001b[38;5;28mself\u001b[39m.labels[idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DS\\My projects\\Wafer defect detection\\build\\venv\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    920\u001b[39m mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)\n\u001b[32m    921\u001b[39m std = torch.as_tensor(std, dtype=dtype, device=tensor.device)\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, leading to division by zero.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mean.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "early_stop_patience = 15\n",
    "\n",
    "best_val_acc = 0\n",
    "early_stop_counter = 0\n",
    "\n",
    "checkpoint_path = os.path.join(Cfg.out_dir, \"checkpoint_last.pt\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=Cfg.device if Cfg.device != \"auto\" else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    best_val_acc = checkpoint.get(\"best_val_acc\", 0.0)\n",
    "    best_val_f1 = checkpoint.get(\"best_val_f1\", 0.0)\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    best_val_acc = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    start_epoch = 0\n",
    "\n",
    "model.to(Cfg.device)\n",
    "\n",
    "for epoch in range(start_epoch, Cfg.epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_losses, y_true_train, y_pred_train = [], [], []\n",
    "\n",
    "    print(f\"Device for model parameters: {next(model.parameters()).device}\")\n",
    "\n",
    "    train_loader = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Cfg.epochs}\", ncols=80)\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        images, labels = images.float().to(Cfg.device), labels.to(Cfg.device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_pred_train.extend(preds.cpu().numpy())\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_loss = np.mean(train_losses)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses, y_true_val, y_pred_val = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.float().to(Cfg.device), labels.to(Cfg.device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_losses.append(loss.item())\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            y_true_val.extend(labels.cpu().numpy())\n",
    "            y_pred_val.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(y_true_val, y_pred_val)\n",
    "    val_f1 = f1_score(y_true_val, y_pred_val, average=\"macro\")\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{Cfg.epochs}] Train Loss: {train_loss:.4f} Train Acc: {train_acc:.4f} Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # if val_acc > best_val_acc:\n",
    "    #     best_val_acc = val_acc  # <-- this update must happen!\n",
    "    #     torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "        # Save checkpoint\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"best_val_acc\": best_val_acc,   # save the best metric\n",
    "        \"best_val_f1\": best_val_f1\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    # # Early stopping logic\n",
    "    # if val_acc > best_val_acc:\n",
    "    #     best_val_acc = val_acc\n",
    "    #     early_stop_counter = 0\n",
    "    #     torch.save(model.state_dict(), os.path.join(Cfg.out_dir, \"best_model.pt\"))\n",
    "    # else:\n",
    "    #     early_stop_counter += 1\n",
    "    #     if early_stop_counter >= early_stop_patience:\n",
    "    #         print(\"Early stopping triggered.\")\n",
    "    #         break\n",
    "\n",
    "        # Early stopping logic\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), os.path.join(Cfg.out_dir, \"best_model.pt\"))\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106f54a",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(Cfg.out_dir, \"best_model.pt\")))\n",
    "model.eval()\n",
    "y_true_test, y_pred_test = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.float().to(Cfg.device), labels.to(Cfg.device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "        y_pred_test.extend(preds.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(y_true_test, y_pred_test)\n",
    "test_f1 = f1_score(y_true_test, y_pred_test, average=\"macro\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} | Test Macro F1: {test_f1:.4f}\")\n",
    "print(classification_report(y_true_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7c33e",
   "metadata": {},
   "source": [
    "### ONNX export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98668357",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, Cfg.img_size, Cfg.img_size).to(Cfg.device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    os.path.join(Cfg.out_dir, \"wafer.onnx\"),\n",
    "    opset_version=12,\n",
    ")\n",
    "print(\"Exported ONNX model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88c971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
